services:
  redis:
    image: redis:7.2-alpine
    container_name: bricksllm-redis
    restart: unless-stopped
    ports:
      - "${REDIS_HOST_PORT:-6380}:6379"
    command: redis-server --save 20 1 --loglevel warning --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - bricksllm-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  mongo:
    image: mongo:7
    container_name: bricksllm-mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - bricksllm-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", 'db.adminCommand("ping")']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: bricksllm-qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__LOG_LEVEL=INFO
    networks:
      - bricksllm-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "bash -c 'exec 3<>/dev/tcp/127.0.0.1/6333 && echo -e \"GET /readyz HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n\" >&3 && cat <&3 | grep \"200 OK\" || exit 1'",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  postgresql:
    image: postgres:16.1-alpine
    container_name: bricksllm-postgresql
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRESQL_USERNAME:-postgres}
      POSTGRES_PASSWORD: ${POSTGRESQL_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRESQL_DB:-bricksllm}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRESQL_HOST_PORT:-5433}:5432"
    volumes:
      - postgresql_data:/var/lib/postgresql/data
    networks:
      - bricksllm-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRESQL_USERNAME:-postgres} -d ${POSTGRESQL_DB:-bricksllm}",
        ]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  llama-server:
    image: ${LLAMA_IMAGE}
    container_name: bricksllm-llama
    restart: unless-stopped
    runtime: nvidia
    depends_on:
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
      mongo:
        condition: service_healthy
    environment:
      CUDA_VISIBLE_DEVICES: ${GPU_DEVICE_IDS:-0}
      SYSTEM_PROMPT: ${SYSTEM_PROMPT}
    ports:
      - "${LLAMA_HOST_PORT:-5002}:5002"
    volumes:
      - ${LOCAL_MODEL_PATH:-./models}:/models
      - ./llama_entrypoint.sh:/app/entrypoint.sh
      - ./chat_template.jinja2.template:/app/chat_template.jinja2.template
    networks:
      - bricksllm-network
    entrypoint: ["/app/entrypoint.sh", "/app/llama-server"]
    command:
      - -m
      - /models/${HF_FILE}
      - -c
      - "${CONTEXT_SIZE:-8192}"
      - --host
      - "0.0.0.0"
      - --port
      - "5002"
      - --n-gpu-layers
      - "${N_GPU_LAYERS:-99}"
      - --temp
      - "${TEMPERATURE:-0.7}"
      - --top-p
      - "${TOP_P:-0.9}"
      - --repeat-penalty
      - "${REPEAT_PENALTY:-1.1}"
      - -n
      - "${NUM_PREDICT:-2048}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]

  bricksllm:
    build:
      context: .
      dockerfile: Dockerfile.prod
    container_name: bricksllm-gateway
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      postgresql:
        condition: service_healthy
      # llama-server:
      #   condition: service_healthy
    environment:
      POSTGRESQL_HOSTS: postgresql
      POSTGRESQL_PORT: 5432
      POSTGRESQL_DB_NAME: ${POSTGRESQL_DB:-bricksllm}
      POSTGRESQL_USERNAME: ${POSTGRESQL_USERNAME:-postgres}
      POSTGRESQL_PASSWORD: ${POSTGRESQL_PASSWORD:-postgres}
      POSTGRESQL_READ_TIME_OUT: ${POSTGRESQL_READ_TIME_OUT:-2s}
      POSTGRESQL_WRITE_TIME_OUT: ${POSTGRESQL_WRITE_TIME_OUT:-1s}
      REDIS_HOSTS: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_READ_TIME_OUT: ${REDIS_READ_TIME_OUT:-1s}
      REDIS_WRITE_TIME_OUT: ${REDIS_WRITE_TIME_OUT:-1s}
      IN_MEMORY_DB_UPDATE_INTERVAL: ${IN_MEMORY_DB_UPDATE_INTERVAL:-5s}
      STATS_PROVIDER: ${STATS_PROVIDER:-}
      AMAZON_SECRET_ARN: ${AMAZON_SECRET_ARN:-}
      AMAZON_REGION: ${AMAZON_REGION:-}
      PROXY_TIMEOUT: ${PROXY_TIMEOUT:-600s}
      NUMBER_OF_EVENT_MESSAGE_CONSUMERS: ${NUMBER_OF_EVENT_MESSAGE_CONSUMERS:-3}
    ports:
      - "${BRICKSLLM_ADMIN_PORT:-8001}:8001"
      - "${BRICKSLLM_PROXY_PORT:-8002}:8002"
    volumes:
      - bricksllm_logs:/var/log/bricksllm
    networks:
      - bricksllm-network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8001/api/health",
        ]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    command: ["-m", "${BRICKSLLM_MODE:-production}"]

  swagger-ui:
    image: swaggerapi/swagger-ui
    container_name: bricksllm-swagger
    restart: unless-stopped
    environment:
      SWAGGER_JSON: /docs/admin.yaml
    volumes:
      - ./docs/admin.yaml:/docs/admin.yaml
    ports:
      - "${SWAGGER_HOST_PORT:-8082}:8080"
    networks:
      - bricksllm-network

  frontend-ui:
    build:
      context: ./frontend-huggingface
      dockerfile: Dockerfile
    container_name: frontend-UI
    restart: unless-stopped
    environment:
      - PUBLIC_APP_NAME=DictaLM Chat
      - PUBLIC_APP_ASSETS=chatui
      - PUBLIC_APP_COLOR=blue
      - PUBLIC_APP_DESCRIPTION=A chat interface for DictaLM
      - PUBLIC_APP_DATA_SHARING=1
      - PUBLIC_APP_DISCLAIMER=0
      - MONGODB_URL=mongodb://mongo:27017/chat-ui
      - HF_TOKEN=${HF_TOKEN:-}
      - DOCKER_ENV=true
      - OPENAI_BASE_URL=http://bricksllm:8002/api/custom/providers/llama-cpp-root
      - OPENAI_API_KEY=${BRICKSLLM_API_KEY:-sk-bricksllm-frontend-llama-key-explicit}
      - ENABLE_CONFIG_MANAGER=false
      - ORIGIN=http://localhost:8004
      - LLM_ROUTER_ENABLE_TOOLS=true
      - LLM_ROUTER_TOOLS_MODEL=DictaLM-3.0-24B-Thinking.i1-Q4_K_M.gguf
      - 'MODELS=[{"id":"DictaLM-3.0-24B-Thinking.i1-Q4_K_M.gguf","name":"DictaLM 3.0 24B","endpoints":[{"type":"openai","baseURL":"http://bricksllm:8002/api/custom/providers/llama-cpp-root"}],"supportsTools":true}]'
      - 'MCP_SERVERS=[{"name":"Everything","url":"http://mcp-sse-proxy:3100/everything/sse"},{"name":"Context7","url":"https://mcp.context7.com/mcp"},{"name":"Docker","url":"http://mcp-sse-proxy:3100/docker/sse"},{"name":"Sequential Thinking","url":"http://mcp-sse-proxy:3100/sequential-thinking/sse"},{"name":"Git","url":"http://mcp-sse-proxy:3100/git/sse"},{"name":"Fetch","url":"http://mcp-sse-proxy:3100/fetch/sse"},{"name":"Time","url":"http://mcp-sse-proxy:3100/time/sse"},{"name":"Memory","url":"http://mcp-sse-proxy:3100/memory/sse"},{"name":"Filesystem","url":"http://mcp-sse-proxy:3100/filesystem/sse"},{"name":"Perplexity","url":"http://mcp-sse-proxy:3100/perplexity/sse"},{"name":"Tavily Search","url":"http://mcp-sse-proxy:3100/Tavily/sse"},{"name":"YouTube Summarizer","url":"http://mcp-sse-proxy:3100/youtube-video-summarizer/sse"},{"name":"DataGov Israel","url":"http://mcp-sse-proxy:3100/datagov/sse"},{"name":"Docling","url":"http://mcp-sse-proxy:3100/docling/sse"}]'
      # RAG Pipeline Configuration
      - DOCUMENT_RAG_ENABLED=true
      - EMBEDDING_SERVICE_URL=http://dicta-retrieval:5005
      - RERANKER_SERVICE_URL=http://dicta-retrieval:5006
      - DOCLING_SERVER_URL=http://docling:5001
      - RERANKER_THRESHOLD=0.7
      - MAX_CONTEXT_CHUNKS=10
      - CONTEXT_TOKEN_BUDGET=8000
      # Memory System Configuration
      - MEMORY_SYSTEM_ENABLED=${MEMORY_SYSTEM_ENABLED:-true}
      - MEMORY_UI_ENABLED=${MEMORY_UI_ENABLED:-true}
      - MEMORY_QDRANT_ENABLED=${MEMORY_QDRANT_ENABLED:-true}
      - MEMORY_BM25_ENABLED=${MEMORY_BM25_ENABLED:-true}
      - MEMORY_RERANK_ENABLED=${MEMORY_RERANK_ENABLED:-true}
      - MEMORY_OUTCOME_ENABLED=${MEMORY_OUTCOME_ENABLED:-true}
      - MEMORY_PROMOTION_ENABLED=${MEMORY_PROMOTION_ENABLED:-true}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-memories_v1}
      - QDRANT_VECTOR_SIZE=${QDRANT_VECTOR_SIZE:-768}
      - MEMORY_INITIAL_SCORE=${MEMORY_INITIAL_SCORE:-0.5}
      - MEMORY_POSITIVE_BOOST=${MEMORY_POSITIVE_BOOST:-0.2}
      - MEMORY_NEGATIVE_PENALTY=${MEMORY_NEGATIVE_PENALTY:-0.3}
      - MEMORY_TOP_K=${MEMORY_TOP_K:-10}
      - MEMORY_SEARCH_LIMIT=${MEMORY_SEARCH_LIMIT:-20}
      - MEMORY_LLM_BASE_URL=http://bricksllm:8002/v1
      - MEMORY_LLM_MODEL=${MEMORY_LLM_MODEL:-dictalm-3.0}
    ports:
      - "8004:3000"
    volumes:
      - ./frontend-huggingface:/app
      - /app/node_modules
      - mcp_uploads:/app/uploads
    depends_on:
      - mongo
      - mcp-sse-proxy
      - qdrant
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - bricksllm-network
    command: ["npm", "run", "dev", "--", "--host", "0.0.0.0", "--port", "3000"]

  mcp-sse-proxy:
    build:
      context: ./mcp-sse-proxy
      dockerfile: Dockerfile
    container_name: mcp-sse-proxy
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      # Configuration
      - ./mcp-sse-proxy/config:/app/config
      # Docker socket for mcp-server-docker
      - /var/run/docker.sock:/var/run/docker.sock
      # Persistent data for MCP servers
      - mcp_memory_data:/app/data/memory
      - mcp_uploads:/app/uploads
      - mcp_sandbox:/app/sandbox
      # DataGov MCP code and cache
      - ./datagov:/app/datagov
      - ./datagov/cache:/app/data/datagov
      # Docling MCP code and cache
      - ./docling_mcp:/app/docling_mcp
      - docling_mcp_cache:/app/data/docling
    environment:
      - PORT=3100
      - CONFIG_PATH=/app/config/servers.json
      - NODE_ENV=production
      # API Keys for external MCP services
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY:-}
      - TAVILY_API_KEY=${TAVILIY_SEARCH_API_KEY:-}
      - SMITHERY_API_KEY=${SMITHERY_API_KEY:-}
      - DATAGOV_PROXY_URL=${DATAGOV_PROXY_URL:-}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - bricksllm-network

  docling:
    env_file: .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    image: quay.io/docling-project/docling-serve-cu128
    container_name: dicta-docling
    ports:
      - 5001:5001
    expose:
      - 5001
    volumes:
      - docling-cache:/root/.cache/docling
      - ./docling/gradio_ui.py:/opt/app-root/src/docling_serve/gradio_ui.py:ro
      - ./docling/Hebrew.traineddata:/root/.cache/docling/tessdata/Hebrew.traineddata
      - ./docling/tesseract:/app/tesseract_custom
      - ./UPLOADED_FILES:/opt/app-root/src/docling_serve/uploaded_files
      # Shared volume for frontend uploads - enables Docling to access files via MCP
      - mcp_uploads:/app/uploads
    environment:
      - DOCLING_SERVE_ENABLE_UI=true
      - NVIDIA_VISIBLE_DEVICES=all
      - DOCLING_SERVE_ENABLE_REMOTE_SERVICES=true
      - OMP_NUM_THREADS=24
      - MKL_NUM_THREADS=24
      - OPENBLAS_NUM_THREADS=24
      - NUMBA_NUM_THREADS=24
      - PYTORCH_NUM_THREADS=24
      - TF_NUM_INTRAOP_THREADS=24
      - TF_NUM_INTEROP_THREADS=2
      - DOCLING_SERVE_MAX_SYNC_WAIT=1800
      - DOCLING_SERVE_TIMEOUT=3600
      - UVICORN_TIMEOUT_KEEP_ALIVE=65
      - UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=30
      - GRADIO_MCP_SERVER=true
      - MAX_FILE_SIZE=${MAX_FILE_SIZE}
      - MAX_NUM_PAGES=${MAX_NUM_PAGES}
      - TESSDATA_PREFIX=/root/.cache/docling/tessdata
    runtime: nvidia
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - bricksllm-network

  dicta-retrieval:
    build:
      context: .
      dockerfile: Dockerfile.BAAI
      args:
        - POETRY_INSTALL_ARGS=
    container_name: dicta-retrieval
    hostname: dicta-retrieval
    environment:
      - FASTAPI_HOST=0.0.0.0
      - FASTAPI_PORT=5005
      - RERANKING_PORT=5006
      - LOG_LEVEL=INFO
      - DEVICE=cuda
      - MODEL_IDLE_TIMEOUT=0
      - USE_FP16=true
      - EMBEDDING_MODEL_NAME=${EMBEDDINGS_MODEL_PATH:-/app/models/embeddings/bge-m3-f16.gguf}
      - RERANKER_MODEL_NAME=${RERANKER_MODEL_NAME:-/app/models/reranking/bge-reranker-v2-m3-q8_0.gguf}
      - EMBEDDINGS_MODEL_CTX_SIZE=${EMBEDDINGS_MODEL_CTX_SIZE:-8192}
      - EMBEDDINGS_MODEL_BATCH_SIZE=${EMBEDDINGS_MODEL_BATCH_SIZE:-512}
      - EMBEDDINGS_MODEL_UBATCH_SIZE=${EMBEDDINGS_MODEL_UBATCH_SIZE:-128}
      - EMBEDDINGS_MODEL_THREADS=${EMBEDDINGS_MODEL_THREADS:-8}
      - EMBEDDINGS_MODEL_N_GPU_LAYERS=${EMBEDDINGS_MODEL_N_GPU_LAYERS:--1}
      - EMBEDDINGS_MODEL_MAIN_GPU=${EMBEDDINGS_MODEL_MAIN_GPU:-0}
      - RERANKER_MODEL_CTX_SIZE=${RERANKER_MODEL_CTX_SIZE:-8192}
      - RERANKER_MODEL_BATCH_SIZE=${RERANKER_MODEL_BATCH_SIZE:-512}
      - RERANKER_MODEL_UBATCH_SIZE=${RERANKER_MODEL_UBATCH_SIZE:-128}
      - RERANKER_MODEL_THREADS=${RERANKER_MODEL_THREADS:-8}
      - RERANKER_MODEL_N_GPU_LAYERS=${RERANKER_MODEL_N_GPU_LAYERS:--1}
      - RERANKER_MODEL_MAIN_GPU=${RERANKER_MODEL_MAIN_GPU:-0}
    ports:
      - "5005:5005"
      - "5006:5006"
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-c",
          "curl -f http://localhost:5005/health && curl -f http://localhost:5006/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./.models:/app/models
    runtime: nvidia
    networks:
      - bricksllm-network

networks:
  bricksllm-network:
    driver: bridge
    ipam:
      config:
        - subnet: ${NETWORK_SUBNET:-172.30.0.0/16}

volumes:
  redis_data:
    driver: local
  postgresql_data:
    driver: local
  mongo_data:
    driver: local
  qdrant_data:
    driver: local
  huggingface_cache:
    driver: local
  vllm_logs:
    driver: local
  bricksllm_logs:
    driver: local
  mcp_memory_data:
    driver: local
  mcp_uploads:
    driver: local
  mcp_sandbox:
    driver: local
  docling-cache:
    driver: local
  docling_mcp_cache:
    driver: local
