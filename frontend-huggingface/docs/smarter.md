# Smarter Tool Orchestration: Enterprise-Grade Methods

This document catalogs all the intelligent methods implemented to make the model's tool usage smarter, more reliable, and user-friendly.

---

## Table of Contents

1. [Tool Intelligence Registry](#1-tool-intelligence-registry)
2. [Parameter Normalization Registry](#2-parameter-normalization-registry)
3. [Cascade Fallback System](#3-cascade-fallback-system)
4. [Graceful Error Handling](#4-graceful-error-handling)
5. [Hebrew Intent Detection](#5-hebrew-intent-detection)
6. [Best-in-Class Tool Selection](#6-best-in-class-tool-selection)
7. [Smart Timeout Management](#7-smart-timeout-management)
8. [Tool Capability Awareness](#8-tool-capability-awareness)
9. [Tool Name Normalization](#9-tool-name-normalization)
10. [Loop Detection & Prevention](#10-loop-detection--prevention)

---

## 1. Tool Intelligence Registry

**File:** `src/lib/server/textGeneration/mcp/toolIntelligenceRegistry.ts`

### What It Does

Centralized metadata for ALL MCP tools including latency characteristics, fallback chains, user-friendly messages, and intent signals.

### Key Data Structure

```typescript
interface ToolIntelligence {
	name: string;
	patterns: RegExp[]; // Match tool name variants
	mcpServer: string; // Which MCP server
	displayName: string; // User-friendly name (Hebrew)
	priority: number; // 0-100 score
	fallbackChain: string[]; // Tools to try if this fails
	conflictsWith: string[]; // Mutually exclusive tools
	latency: {
		typical: number; // Expected ms
		timeout: number; // Max wait ms
		userFeedbackDelay: number; // Show spinner after ms
		tier: "fast" | "medium" | "slow" | "very_slow";
	};
	response: {
		typicalTokens: number;
		maxTokens: number;
		structured: boolean;
		requiresSummarization: boolean;
	};
	messages: {
		progress: string; // "××—×¤×© ×‘×××’×¨×™ ×”××™×“×¢..."
		noResults: string;
		suggestion: string;
		gracefulFailure: string;
	};
	intentSignals: {
		keywords: RegExp; // Hebrew + English patterns
		weight: number; // Score boost when matched
		exclusive?: boolean; // Use ONLY this tool if matched
	};
}
```

### Smart Methods

| Method                            | Purpose                                      |
| --------------------------------- | -------------------------------------------- |
| `getToolIntelligence(name)`       | Get metadata by tool name                    |
| `getFallbackChain(name)`          | Get ordered fallback list                    |
| `getLatencyTier(name)`            | Categorize speed expectation                 |
| `scoreToolForQuery(name, query)`  | Score tool relevance 0-200                   |
| `rankToolsForQuery(query, tools)` | Sort by relevance + handle exclusive matches |

---

## 2. Parameter Normalization Registry

**File:** `src/lib/server/textGeneration/mcp/toolParameterRegistry.ts`

### What It Does

Automatically transforms model-generated parameters to match what each tool expects, preventing "missing parameter" errors.

### Key Features

#### Alias Mapping

Models often use different parameter names. The registry maps them:

```typescript
// Perplexity tools
"query" â†’ "messages" (with proper format)
"question" â†’ "messages"
"prompt" â†’ "messages"

// Filesystem tools
"file" â†’ "path"
"filepath" â†’ "path"
"file_path" â†’ "path"

// Git tools
"path" â†’ "repo_path"
"repository" â†’ "repo_path"

// Docker tools
"container_id" â†’ "container"
"name" â†’ "container"
```

#### Type Coercion

Automatically converts types:

```typescript
// String to number
"5" â†’ 5 (for days, limit, etc.)

// String to boolean
"true" â†’ true
"false" â†’ false

// Enum validation
"general" | "news" (for Tavily topic)
```

#### Default Values

Injects required defaults:

```typescript
// Tavily search
search_depth: "advanced";
include_answer: true;

// Perplexity
return_related_questions: false;
```

### Normalization Flow

```
1. Copy ALL original args (never lose data)
2. Apply alias mappings
3. Coerce types
4. Inject defaults
5. Return normalized + warnings
```

---

## 3. Cascade Fallback System

**File:** `src/lib/server/textGeneration/mcp/toolInvocation.ts`

### What It Does

When a primary tool fails, automatically tries fallback tools in priority order before showing an error.

### Fallback Chains

```
Israeli Government Data:
  datagov_query â†’ perplexity-search â†’ tavily-search

Deep Research:
  perplexity-research â†’ perplexity-ask â†’ tavily-search

Quick Search:
  tavily-search â†’ perplexity-search â†’ fetch
```

### Implementation

```typescript
// After primary tool fails with recoverable error
if (isRecoverableError(message)) {
	const fallbackChain = getFallbackChain(originalTool);

	for (const fallbackTool of fallbackChain) {
		// Check if fallback is available
		const fallbackMapping = mapping[fallbackTool];
		if (!fallbackMapping) continue;

		// Try fallback
		try {
			const result = await callMcpTool(fallbackTool, args);
			return result; // Success!
		} catch {
			continue; // Try next fallback
		}
	}
}
// All failed â†’ show graceful error
```

### Non-Recoverable Errors (Skip Fallback)

- `unauthorized` / `forbidden` (auth issues)
- `invalid api key` (configuration issues)

---

## 4. Graceful Error Handling

**File:** `src/lib/server/textGeneration/mcp/toolInvocation.ts`

### What It Does

Users NEVER see raw errors. Every error is transformed into a helpful Hebrew message explaining:

1. **WHAT** happened (which service failed)
2. **WHY** it likely failed (possible reason)
3. **WHAT TO DO** (actionable next step)

### Error Categories

| Error Type | Example Message                                                                                                                   |
| ---------- | --------------------------------------------------------------------------------------------------------------------------------- |
| Timeout    | `â±ï¸ **×”××—×§×¨ ×œ×§×— ×™×•×ª×¨ ××“×™ ×–××Ÿ**\n\n×”×©×™×¨×•×ª Perplexity ××‘×¦×¢ ×—×™×¤×•×© ××¢××™×§ ×©×œ×¤×¢××™× ×“×•×¨×© ×–××Ÿ ×¨×‘.\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ × ×¡×” ×©××œ×” ×§×¦×¨×” ×™×•×ª×¨` |
| Connection | `ğŸ”Œ **×©×™×¨×•×ª Tavily ××™× ×• ×–××™×Ÿ ×›×¨×’×¢**\n\n×™×™×ª×›×Ÿ ×©×™×© ×ª×§×œ×” ×–×× ×™×ª.\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ × ×¡×” ×©×•×‘ ×‘×¢×•×“ ××¡×¤×¨ ×©× ×™×•×ª`                         |
| Not Found  | `ğŸ” **×œ× × ××¦× ××™×“×¢ ×‘×××’×¨×™× ×”×××©×œ×ª×™×™×**\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ × ×¡×” ××™×œ×•×ª ××¤×ª×— ×¨×©××™×•×ª`                                                 |
| Validation | `ğŸ“ **×—×¡×¨ ××™×“×¢ ×œ×‘×™×¦×•×¢ ×”×¤×¢×•×œ×”**\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ × ×¡×— ××ª ×”×‘×§×©×” ×‘×¦×•×¨×” ××¤×•×¨×˜×ª ×™×•×ª×¨`                                                |
| Rate Limit | `âš¡ **×”×’×¢×ª ×œ××’×‘×œ×ª ×‘×§×©×•×ª**\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ ×”××ª×Ÿ ×“×§×” ×•× ×¡×” ×©×•×‘`                                                                  |
| Auth       | `ğŸ” **×‘×¢×™×™×ª ×”×¨×©××”**\n\n**××” ×œ×¢×©×•×ª:**\nâ€¢ ×¤× ×” ×œ×× ×”×œ ×”××¢×¨×›×ª`                                                                         |

### Tool-Specific Context

```typescript
// DataGov timeout
if (toolName.includes("datagov")) {
	return (
		`â±ï¸ **×”×’×™×©×” ×œ×××’×¨×™ ×”××™×“×¢ ×”×××©×œ×ª×™×™× ××¨×›×” ×–××Ÿ ×¨×‘**\n\n` +
		`×”×××’×¨×™× ×”×××©×œ×ª×™×™× ××›×™×œ×™× ××™×œ×™×•× ×™ ×¨×©×•××•×ª...`
	);
}

// Perplexity research timeout
if (toolName.includes("research")) {
	return `â±ï¸ **×”××—×§×¨ ×œ×§×— ×™×•×ª×¨ ××“×™ ×–××Ÿ**\n\n` + `×”×©×™×¨×•×ª Perplexity ××‘×¦×¢ ×—×™×¤×•×© ××¢××™×§...`;
}
```

---

## 5. Hebrew Intent Detection

**File:** `src/lib/server/textGeneration/mcp/toolFilter.ts`
**File:** `src/lib/server/textGeneration/utils/hebrewIntentDetector.ts`

### What It Does

Detects user intent from Hebrew keywords to select the optimal tool.

### Hebrew Keywords â†’ Tool Scoring

```typescript
// Research intent
/××—×§×¨|×œ×—×§×•×¨|× ×™×ª×•×— ××¢××™×§|×œ×¢×•××§|××§×™×£|××¤×•×¨×˜/ â†’ perplexity-research (+100)

// Government data intent (EXCLUSIVE)
/×××’×¨ ×¨×©××™|× ×ª×•× ×™× ×××©×œ×ª×™|×œ×©×›×ª ×”×¡×˜×˜×™×¡×˜×™×§×”|××©×¨×“ ×”/ â†’ datagov_query (+100, exclusive)

// Quick search intent
/×—×¤×©|××¦×|×—×“×©×•×ª|×¢×“×›×•×Ÿ/ â†’ tavily-search (+80)

// Explanation intent
/×”×¡×‘×¨|×¡×¤×¨ ×œ×™|××” ×–×”|××™×š ×¢×•×‘×“/ â†’ perplexity-ask (+90)
```

### Exclusive Matching

When `exclusive: true` is set, ONLY that tool is used:

```typescript
// User asks about official Israeli data
"×›××” ×¨×›×‘×™× ×—×©××œ×™×™× ×¨×©×•××™× ×‘××©×¨×“ ×”×ª×—×‘×•×¨×”?"
â†’ Matches /××©×¨×“ ×”/ with exclusive=true
â†’ ONLY datagov_query is returned (no alternatives)
```

---

## 6. Best-in-Class Tool Selection

**File:** `src/lib/server/textGeneration/mcp/toolFilter.ts`

### What It Does

When multiple similar tools exist, automatically selects the best one based on intent and priority.

### Perplexity Tool Scoring

```typescript
function selectBestPerplexityTool(query: string): string {
	const scores = {
		"perplexity-research": 0,
		"perplexity-ask": 0,
		"perplexity-search": 0,
		"perplexity-reason": 0,
	};

	// Score based on Hebrew keywords
	if (/××—×§×¨|× ×™×ª×•×— ××¢××™×§/.test(query)) scores["perplexity-research"] += 100;
	if (/×”×¡×‘×¨|×¡×¤×¨ ×œ×™/.test(query)) scores["perplexity-ask"] += 90;
	if (/×—×¤×©|××¦×/.test(query)) scores["perplexity-search"] += 80;
	if (/× ××§|×¦×¢×“ ××—×¨ ×¦×¢×“/.test(query)) scores["perplexity-reason"] += 85;

	// Return highest scorer
	return Object.entries(scores).sort(([, a], [, b]) => b - a)[0][0];
}
```

### Tool Category Priorities

```typescript
const TOOL_PRIORITIES = {
	datagov_query: 95, // Official Israeli data
	"perplexity-research": 100, // Deep research
	"perplexity-ask": 95,
	"perplexity-search": 90,
	"tavily-search": 85,
	fetch: 70,
};
```

---

## 7. Smart Timeout Management

**File:** `src/lib/server/mcp/httpClient.ts`

### What It Does

Applies intelligent timeouts based on tool type - research tools get 5 minutes, quick tools get 60 seconds.

### Timeout Configuration

```typescript
// Default for most tools
const DEFAULT_TIMEOUT_MS = 60_000; // 1 minute

// Extended for research-intensive tools
const EXTENDED_TIMEOUT_TOOLS = [
	"perplexity_research",
	"perplexity_ask",
	"perplexity-research",
	"perplexity-ask",
	"perplexity_reason",
	"perplexity-reason",
	"perplexity_search",
	"perplexity-search",
];
const EXTENDED_TIMEOUT_MS = 300_000; // 5 minutes
```

### Smart Timeout Selection

```typescript
const isExtendedTool = EXTENDED_TIMEOUT_TOOLS.some((t) =>
	tool.toLowerCase().includes(t.toLowerCase())
);
const smartTimeout = isExtendedTool ? EXTENDED_TIMEOUT_MS : DEFAULT_TIMEOUT_MS;
const effectiveTimeout = Math.max(timeoutMs ?? 0, smartTimeout);
```

---

## 8. Tool Capability Awareness

**File:** `src/lib/server/textGeneration/mcp/toolIntelligenceRegistry.ts`
**File:** `src/lib/server/textGeneration/utils/toolPrompt.ts`

### What It Does

Enables the model to describe its capabilities to users and proactively suggest better tools.

### Capability Manifest Generator

```typescript
function generateToolCapabilityManifest(availableTools: string[]): string {
	// Groups tools by category
	// Returns Hebrew + English descriptions
	return `
## ×”×™×›×•×œ×•×ª ×©×œ×™ / My Capabilities

**××—×§×¨ ××¢××™×§ / Deep Research**
  â€¢ Perplexity Deep Research (×œ×•×§×— ×–××Ÿ): ××‘×¦×¢ ××—×§×¨ ××¢××™×§
  â€¢ Perplexity Q&A: ××—×¤×© ×ª×©×•×‘×”

**×—×™×¤×•×© ×‘×¨×©×ª / Web Search**
  â€¢ Tavily Web Search: ××—×¤×© ×‘×¨×©×ª

**××™×“×¢ ×××©×œ×ª×™ / Government Data**
  â€¢ Israel Government Data: ××—×¤×© ×‘×××’×¨×™ ×”××™×“×¢ ×”×××©×œ×ª×™×™×
`;
}
```

### Post-Execution Suggestions

```typescript
function generatePostExecutionSuggestions(usedTool: string, query: string): string {
	// Quick search â†’ Suggest deeper research
	if (usedTool.includes("tavily")) {
		if (/××—×§×¨|× ×™×ª×•×—/.test(query)) {
			return `ğŸ’¡ **×”×¦×¢×”**: ×œ× ×™×ª×•×— ××¢××™×§ ×™×•×ª×¨, ××•×›×œ ×œ×‘×¦×¢ ××—×§×¨ ×¢× Perplexity Research`;
		}
	}

	// DataGov â†’ Suggest context from other sources
	if (usedTool.includes("datagov")) {
		return `ğŸ’¡ **×”×¢×¨×”**: ×”× ×ª×•× ×™× ××’×™×¢×™× ××××’×¨×™ ×”××™×“×¢ ×”×××©×œ×ª×™×™× ×”×¨×©××™×™×.`;
	}

	return "";
}
```

### Prompt Instructions

Added to system prompt:

```
4. **Tool Transparency & Capability Awareness**:
   - When user asks "××” ××ª×” ×™×›×•×œ ×œ×¢×©×•×ª?" â†’ describe available tools
   - After using a tool â†’ mention which tool provided the answer
   - If answer is limited â†’ proactively suggest alternatives
   - Example: "×‘×™×¦×¢×ª×™ ×—×™×¤×•×© ××”×™×¨. ×œ×ª×•×¦××•×ª ××§×™×¤×•×ª ×™×•×ª×¨, ××•×›×œ ×œ×”×¤×¢×™×œ ××ª ×›×œ×™ ×”××—×§×¨ ×”××¢××™×§."
```

---

## 9. Tool Name Normalization

**File:** `src/lib/server/textGeneration/mcp/toolInvocation.ts`

### What It Does

Models generate tool names inconsistently (underscores vs hyphens, case variations). This normalizes them.

### Normalization Variants

```typescript
function normalizeToolName(name: string, mapping: Record<string, any>): string {
	// Direct match
	if (mapping[name]) return name;

	// underscore â†’ hyphen: tavily_search â†’ tavily-search
	const hyphenVariant = name.replace(/_/g, "-");
	if (mapping[hyphenVariant]) return hyphenVariant;

	// hyphen â†’ underscore: tavily-search â†’ tavily_search
	const underscoreVariant = name.replace(/-/g, "_");
	if (mapping[underscoreVariant]) return underscoreVariant;

	// Case-insensitive match
	for (const key of Object.keys(mapping)) {
		if (key.toLowerCase() === name.toLowerCase()) return key;
	}

	return name;
}
```

---

## 10. Loop Detection & Prevention

**File:** `src/lib/server/textGeneration/mcp/loopDetector.ts`

### What It Does

Prevents infinite tool call loops by detecting when the model calls the same tool with the same arguments repeatedly.

### Detection Method

```typescript
interface LoopDetectorService {
	// Semantic hashing of tool calls
	addToolCall(toolName: string, args: Record<string, unknown>): void;

	// Check if we've seen this exact call 3+ times
	isLooping(): boolean;

	// Reset after successful conversation turn
	reset(): void;
}
```

### Limits

- Maximum 3 identical tool calls
- Maximum 10 tool rounds per conversation turn
- Semantic comparison (not just string equality)

---

---

## 11. DataGov Enterprise Intelligence

**Files:** `datagov/server.py`, `datagov/query_builder.py`

This is a comprehensive suite of smart methods specifically designed for querying Israeli government data (data.gov.il). These methods handle the unique challenges of Hebrew language, government data structures, and user intent disambiguation.

### 11.1 Browser Impersonation (Anti-403)

**Problem:** data.gov.il blocks non-browser requests with 403 errors.

**Solution:** Use `curl_cffi` with Chrome 120 fingerprint:

```python
session = requests.Session(impersonate="chrome120")
session.headers.update({
    "Referer": "https://data.gov.il/",
    "User-Agent": "Mozilla/5.0 ... datagov-external-client",
})
```

### 11.2 Query Decomposition

**Problem:** User queries mix WHAT they want with WHERE they want it.

**Solution:** `_decompose_query()` separates subject from location:

```python
"×‘×ª×™ ×—×•×œ×™× ×‘×™×¨×•×©×œ×™×" â†’
{
    "subject_tokens": ["×‘×ª×™", "×—×•×œ×™×"],
    "location_tokens": ["×™×¨×•×©×œ×™×"],
    "expanded_subjects": ["hospital", "×‘×™×ª ×—×•×œ×™×", "×¨×¤×•××”"...]
}
```

### 11.3 Hebrew Morphological Normalization

**Problem:** Hebrew has prefixes (×‘, ×œ, ×, ×”) and plural suffixes (×™×, ×•×ª) that prevent matching.

**Solution:** `get_hebrew_variants()` generates all forms:

```python
"×œ×¨×›×‘×™×" â†’ ["×œ×¨×›×‘×™×", "×¨×›×‘×™×", "×¨×›×‘"]
"×‘×™×¨×•×©×œ×™×" â†’ ["×‘×™×¨×•×©×œ×™×", "×™×¨×•×©×œ×™×"]
```

### 11.4 Bidirectional Expansion Index

**Problem:** One-way expansion (crime â†’ ×¤×©×™×¢×”) doesn't work in reverse (×¤×©×™×¢×” â†’ crime).

**Solution:** `_build_bidirectional_index()` maps ALL synonyms both ways:

```python
# Before: {"crime": ["×¤×©×™×¢×”"]}
# After:  {"crime": {"crime", "×¤×©×™×¢×”"}, "×¤×©×™×¢×”": {"crime", "×¤×©×™×¢×”"}}
```

**22 domains with 3,972 bidirectional terms** in `enterprise_expansions.py`:

- Justice: court, judge, law â†’ ×‘×™×ª ××©×¤×˜, ×©×•×¤×˜, ×—×•×§ (30 keys â†’ 95 terms)
- Healthcare: hospital, clinic â†’ ×‘×™×ª ×—×•×œ×™×, ××¨×¤××” (23 keys â†’ 76 terms)
- Education: school, university â†’ ×‘×™×ª ×¡×¤×¨, ××•× ×™×‘×¨×¡×™×˜×” (27 keys â†’ 94 terms)
- Transportation: vehicle, road, traffic â†’ ×¨×›×‘, ×›×‘×™×©, ×ª× ×•×¢×” (53 keys â†’ 202 terms)
- Finance: budget, tax, bank â†’ ×ª×§×¦×™×‘, ××¡, ×‘× ×§ (37 keys â†’ 109 terms)
- Environment: pollution, climate, nature â†’ ×–×™×”×•×, ××§×œ×™×, ×˜×‘×¢ (39 keys â†’ 126 terms)
- **ENTERPRISE_SUBJECT_EXPANSIONS**: 476 keys â†’ 1,500 terms (dataset-specific keywords)
- And 15 more domains (Agriculture, Communications, Culture, Demographics, Geography, Housing, Immigration, Insurance, Labor, Municipal, Religion, Technology, Tourism, Water, Welfare)

### 11.5 Count Query Detection & Auto-Aggregation

**Problem:** User asks "×›××” ×¨×›×‘×™× ×‘×™×©×¨××œ?" but only gets 20 rows.

**Solution:** `_is_count_query()` + `_calculate_aggregates()`:

```python
# Detects patterns:
count_patterns = [r'\b×›××”\b', r'\b×¡×”"×›\b', r'\btotal\b', r'\bcount\b']

# If matched:
# 1. Auto-increase limit to 100 (get all records)
# 2. Calculate SUM/COUNT for numeric columns
# 3. Include totals in response:
{
    "summary_totals": {
        "×›××•×ª_×¨×›×‘×™×": {"sum": 4500000, "count": 4500000}
    },
    "metadata": {
        "aggregation_note": "Use these totals directly to answer 'how many' questions"
    }
}
```

### 11.6 Enterprise Schema System

**Problem:** API calls to get field names are slow (500ms each). Monolithic JSON files are hard to maintain.

**Solution:** Per-dataset schema files organized by category in `schemas/` directory:

```
schemas/
â”œâ”€â”€ _index.json           # Master lookup: resource_id â†’ file path (1,960 resources)
â”œâ”€â”€ _field_index.json     # Quick field availability lookup
â”œâ”€â”€ _category_index.json  # Category â†’ datasets mapping
â”œâ”€â”€ health/               # 84 health datasets
â”‚   â”œâ”€â”€ serologiclabs.json
â”‚   â”œâ”€â”€ ×‘×ª×™_×—×•×œ×™×.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ transportation/       # 200+ transportation datasets
â”œâ”€â”€ finance/              # Budget, tax, economic data
â””â”€â”€ ... (20 category directories)
```

**Individual Schema Structure:**

```json
{
	"dataset_id": "62c54ef6-49f1-4b5f-bd1e-1e88a5955acd",
	"title": "serologiclabs",
	"organization": "××©×¨×“ ×”×‘×¨×™××•×ª",
	"categories": ["health"],
	"keywords": ["phone", "hospital", "city", "××©×¨×“", "×”×‘×¨×™××•×ª"],
	"resources": [
		{
			"resource_id": "b3c89abc-8e86-4abd-a4f3-a33ebee9fc07",
			"title": "××¢×‘×“×•×ª ×”××‘×¦×¢×•×ª ×‘×“×™×§×•×ª ×¡×¨×•×œ×•×’×™×•×ª",
			"format": "XLSX",
			"fields": [
				{ "name": "city", "type": "text", "semantic": "city" },
				{ "name": "phone", "type": "text", "semantic": "phone" },
				{ "name": "hospital", "type": "text", "semantic": null }
			],
			"total_records": 32
		}
	],
	"field_availability": {
		"has_phone": true,
		"has_address": false,
		"has_location": true,
		"has_email": false
	}
}
```

**Schema includes:**

- Field names, types, and **semantic annotations** (phone, city, address, email, date, coordinate)
- **Keywords extracted from titles and fields** for search matching
- **Field availability flags** for instant filtering (has_phone, has_address)
- **Multiple resources per dataset** with individual field mappings
- **Total record counts** per resource

### 11.7 Semantic Field Mapping

**Problem:** User asks for "phone numbers" but field is named "×˜×œ×¤×•×Ÿ_××•×¡×“".

**Solution:** `get_semantic_field_name()` maps intents to actual fields:

```python
get_semantic_field_name("abc-123", "phone") â†’ "×˜×œ×¤×•×Ÿ_××•×¡×“"
get_semantic_field_name("abc-123", "address") â†’ "×›×ª×•×‘×ª_××œ××”"
```

### 11.8 Field Intent Extraction

**Problem:** User asks "courts with addresses and phone numbers" - need to select only those fields.

**Solution:** `extract_field_intents()` parses English/Hebrew intent:

```python
"hospitals with phone numbers and addresses" â†’
["phone", "address"]

# Then match to schema:
match_fields_to_schema(["phone", "address"], schema_fields) â†’
{
    "matched_fields": ["×˜×œ×¤×•×Ÿ_××•×¡×“", "×›×ª×•×‘×ª_××œ××”"],
    "missing_intents": []
}
```

### 11.9 Field Availability Filtering

**Problem:** 5 datasets match "hospitals" but only 2 have phone numbers.

**Solution:** `filter_by_field_availability()` pre-filters candidates:

```python
# Before: 5 candidates
candidates = filter_by_field_availability(candidates, ["phone", "address"])
# After: 2 candidates (only those with both fields)
```

Uses lightweight `_field_index.json` for fast lookup:

```python
{
    "abc-123": {"has_phone": true, "has_address": true, "has_email": false}
}
```

### 11.10 Enterprise Fallback: Query Rephrasing

**Problem:** Initial query returns no/low-confidence matches.

**Solution:** `rephrase_query()` tries alternative phrasings:

```python
"×¡×˜×˜×™×¡×˜×™×§×ª ×¤×©×™×¢×”" (0.25 confidence) â†’
# Strategy 1: Morphological normalization
"×¡×˜×˜×™×¡×˜×™×§×” ×¤×©×™×¢×”" (0.32)

# Strategy 2: Core subjects only
"×¤×©×™×¢×”" (0.45)

# Strategy 3: English equivalent
"crime" (0.55) âœ“ Success!
```

### 11.11 Subject-First Scoring Algorithm

**Problem:** Location matches dominate results (everything in "×™×¨×•×©×œ×™×" matches).

**Solution:** Subject-first scoring with minimum threshold:

```python
# Weights:
# - Subject match (title): 40%
# - Subject match (name/tags): 30%
# - Hebrew expansion match: 20%
# - Location match: 10% (bonus only)
# - Format preference: 0-30% bonus

# CRITICAL: Skip if subject score < 0.15
if subject_tokens and subject_score < 0.15:
    continue  # Don't return irrelevant location matches
```

### 11.12 Location Filter Values

**Problem:** User says "Jerusalem" but data has "×™×¨×•×©×œ×™×", "JERUSALEM", or "3".

**Solution:** `LOCATION_FILTER_VALUES` maps all variants:

```python
{
    "jerusalem": ["×™×¨×•×©×œ×™×", "Jerusalem", "JERUSALEM", "3"],
    "tel aviv": ["×ª×œ ××‘×™×‘", "Tel Aviv", "TEL AVIV", "5", "×ª×œ-××‘×™×‘"]
}
```

### 11.13 Hebrew Prefix Stripping for Locations

**Problem:** User types "×‘×™×¨×•×©×œ×™×" (in Jerusalem) but data has "×™×¨×•×©×œ×™×".

**Solution:** `_strip_hebrew_prefix()` intelligently strips:

```python
"×‘×™×¨×•×©×œ×™×" â†’ "×™×¨×•×©×œ×™×" (in Jerusalem â†’ Jerusalem)
"×œ×ª×œ ××‘×™×‘" â†’ "×ª×œ ××‘×™×‘" (to Tel Aviv â†’ Tel Aviv)
"××—×™×¤×”" â†’ "×—×™×¤×”" (from Haifa â†’ Haifa)
```

**Smart stripping:** Only strips if remaining word is a known location.

### 11.14 Format Preference Scoring

**Problem:** PDF datasets can't be queried; CSV is best.

**Solution:** Format bonus in scoring:

```python
fmt_bonus = {
    "CSV": 0.15,   # Best - queryable, clean
    "XLSX": 0.12,  # Good - queryable
    "JSON": 0.10,  # Good - structured
    "XML": 0.05,   # OK - structured
    "PDF": 0.02,   # Poor - not queryable
    "API": 0.08    # Good - direct access
}
```

### 11.15 Comprehensive Keyword Index

**Problem:** SUBJECT_EXPANSIONS only covers known terms; new datasets have new keywords.

**Solution:** `_load_keyword_index()` indexes ALL keywords from ALL datasets:

```python
# Indexes every keyword from enterprise_schemas.json
# Maps keyword â†’ [resource_ids]

# If query contains any keyword, those resources get boosted
if rid in keyword_resource_scores:
    resource_score += min(0.25, keyword_resource_scores[rid] * 0.08)
```

### 11.16 Category Suggestion for Vague Queries

**Problem:** User query too vague to match anything.

**Solution:** `get_category_suggestion()` provides guidance:

```python
# If query is too vague:
"Query is too vague. Please specify a domain:
â€¢ ×‘×¨×™××•×ª (health) - hospitals, clinics, medical data
â€¢ ×—×™× ×•×š (education) - schools, students, academic
â€¢ ×ª×—×‘×•×¨×” (transport) - vehicles, roads, traffic
â€¢ ×ª×§×¦×™×‘ (budget) - government spending, finance
..."
```

### 11.17 Resource Scoring Algorithm

**Problem:** Multiple datasets match - which is best?

**Solution:** `_score_resource()` with multi-factor scoring:

```python
def _score_resource(query, ds_title, res_title, fmt, last_modified, tags):
    score = 0.0
    # Title match: +0.4
    if query in ds_title.lower(): score += 0.4
    # Resource match: +0.3
    if query in res_title.lower(): score += 0.3
    # Tag match: +0.2
    if any(query in tag.lower() for tag in tags): score += 0.2
    # Format bonus: +0.05 to +0.30
    score += format_bonus[fmt]
    return min(1.0, score)
```

### 11.18 Markdown Table Formatting

**Problem:** Raw JSON is hard to read in chat.

**Solution:** `_format_as_markdown()` creates readable tables:

```markdown
| ×©×             | ×›×ª×•×‘×ª   | ×˜×œ×¤×•×Ÿ      |
| -------------- | ------- | ---------- |
| ×‘×™×ª ×—×•×œ×™× ×”×“×¡×” | ×™×¨×•×©×œ×™× | 02-1234567 |

**Source**: ×‘×ª×™ ×—×•×œ×™× ×‘×™×©×¨××œ - ×¨×©×™××” ××œ××”
**Records**: 1-20 of 150 | **Format**: CSV

**ğŸ“Š SUMMARY TOTALS:**

- **××¡×¤×¨_××™×˜×•×ª**: 45,000 (from 150 records)

_â˜ï¸ Use these totals to answer 'how many' questions directly._
```

### 11.19 Retry Logic with Graceful Degradation

**Problem:** API sometimes returns 403 or times out.

**Solution:** Retry with graceful fallback:

```python
max_retries = 2
for attempt in range(max_retries + 1):
    try:
        response = _http("GET", "/action/datastore_search", params)
        if response.status_code == 403:
            time.sleep(0.5)
            continue  # Retry
        if response.status_code == 404:
            return {"error": "Resource not found", "suggestion": "Try different format"}
        break
    except Exception:
        if attempt < max_retries:
            time.sleep(0.5)
            continue
```

### 11.20 Pre-loaded Resource Map

**Problem:** Searching the API for datasets is slow.

**Solution:** Pre-indexed `resources_map.json` loaded at startup:

```python
# Loaded once at startup (1187 datasets)
RESOURCES_MAP = {}
if os.path.exists(MAP_PATH):
    RESOURCES_MAP = json.load(f)
    print(f"Loaded {len(RESOURCES_MAP['datasets'])} datasets")

# Instant local search
candidates = suggest_for_query(query, RESOURCES_MAP, limit=5)
```

---

## Summary: The Smarter Tool Stack

| Layer           | Component               | Smart Behavior                           |
| --------------- | ----------------------- | ---------------------------------------- |
| **Selection**   | Hebrew Intent Detection | Understands Hebrew queries               |
| **Selection**   | Best-in-Class Selection | Picks optimal tool from similar options  |
| **Selection**   | Exclusive Matching      | Forces single tool when intent is clear  |
| **Preparation** | Parameter Normalization | Fixes model parameter mistakes           |
| **Preparation** | Tool Name Normalization | Handles underscore/hyphen/case variants  |
| **Execution**   | Smart Timeouts          | 5 min for research, 1 min for quick      |
| **Execution**   | Cascade Fallback        | Tries alternatives before failing        |
| **Execution**   | Loop Detection          | Prevents infinite loops                  |
| **Response**    | Graceful Errors         | Hebrew messages with actionable guidance |
| **Response**    | Capability Awareness    | Model can describe and suggest tools     |
| **DataGov**     | Query Decomposition     | Separates subject from location          |
| **DataGov**     | Hebrew Morphology       | Strips prefixes, handles plurals         |
| **DataGov**     | Bidirectional Expansion | 3,972 terms across 22 domains            |
| **DataGov**     | Auto-Aggregation        | Detects "×›××”" and calculates totals      |
| **DataGov**     | Enterprise Schemas      | Pre-computed field metadata              |
| **DataGov**     | Semantic Field Mapping  | "phone" â†’ "×˜×œ×¤×•×Ÿ_××•×¡×“"                   |
| **DataGov**     | Query Rephrasing        | Tries alternative phrasings on fail      |
| **DataGov**     | Subject-First Scoring   | Prioritizes WHAT over WHERE              |
| **DataGov**     | Format Preference       | CSV > XLSX > JSON > XML > PDF            |
| **DataGov**     | Pre-loaded Resource Map | 1187 datasets indexed locally            |

---

## Files Reference

| File                                   | Purpose                                                    |
| -------------------------------------- | ---------------------------------------------------------- |
| `toolIntelligenceRegistry.ts`          | Central metadata for all tools                             |
| `toolParameterRegistry.ts`             | Parameter alias mapping & normalization                    |
| `toolInvocation.ts`                    | Execution, fallback, error handling                        |
| `toolFilter.ts`                        | Intent detection, tool selection                           |
| `toolPrompt.ts`                        | System prompt with capabilities                            |
| `httpClient.ts`                        | Timeout management                                         |
| `loopDetector.ts`                      | Infinite loop prevention                                   |
| `hebrewIntentDetector.ts`              | Hebrew language detection                                  |
| `datagov/server.py`                    | DataGov MCP server with all tools                          |
| `datagov/query_builder.py`             | Query decomposition, scoring, expansion                    |
| `datagov/enterprise_expansions.py`     | 22 domains, 3,972 bidirectional Hebrewâ†”English terms      |
| `datagov/schemas/`                     | **1,190 per-dataset schema files** in 20 category dirs     |
| `datagov/schemas/_index.json`          | Master lookup: resource_id â†’ schema file (1,960 resources) |
| `datagov/schemas/_field_index.json`    | Fast field availability lookup (has_phone, has_address)    |
| `datagov/schemas/_category_index.json` | Category â†’ datasets mapping                                |
| `datagov/resources_map.json`           | Local index for instant dataset search                     |

---

## Statistics

| Metric                        | Value                                                                        |
| ----------------------------- | ---------------------------------------------------------------------------- |
| Total Smart Methods           | **30+**                                                                      |
| DataGov Datasets Indexed      | **1,187**                                                                    |
| Individual Schema Files       | **1,190** (organized in 20 categories)                                       |
| Resources with Field Metadata | **1,960**                                                                    |
| Bidirectional Expansion Terms | **3,972** (22 domains)                                                       |
| Dataset Tags Indexed          | **1,527** unique                                                             |
| Title Keywords Indexed        | **3,963** unique                                                             |
| **Total Searchable Terms**    | **~9,500+**                                                                  |
| Semantic Domains              | **22**                                                                       |
| Semantic Field Types          | **6** (phone, address, email, date, city, coordinate)                        |
| Tool Categories               | **6** (Research, Search, Data, Files, Dev, Utility)                          |
| Fallback Chains               | **3** main chains                                                            |
| Error Categories              | **7** (timeout, connection, not found, validation, rate limit, auth, server) |

---

_Generated: December 2024_
_Enterprise Tool Orchestration System v1.0_
